version: '3.8'

services:
  gpu-build:
    image: gpu-ai-inference-server:latest
    build:
      context: .
      dockerfile: docker/Dockerfile.gpu
    volumes:
      - .:/workspace
      - build-volume:/workspace/build
    runtime: nvidia  # Required for GPU access
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    command: /bin/bash -c "scripts/build_inference_engine.sh --run-tests"

volumes:
  build-volume:  # Persistent volume for build artifacts