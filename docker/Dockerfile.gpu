#TODO: Reformat this base on Dockerfile but for GPUs before deploy to GPU cloud
FROM nvidia/cuda:12.1.0-devel-ubuntu22.04

# Add metadata
LABEL maintainer="oscar.william.chen@gmail.com"
LABEL version="1.0"
LABEL description="GPU Inference Server with CUDA support"

# Set environment variables
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV PATH="/usr/local/go/bin:${PATH}"
ENV GOPATH="/go"
ENV PATH="${GOPATH}/bin:${PATH}"

# Install system dependencies in a single layer
RUN apt-get update && apt-get install -y \
    build-essential \
    cmake \
    git \
    wget \
    python3 \
    python3-pip \
    && rm -rf /var/lib/apt/lists/* \
    && python3 -m pip install --upgrade pip==24.2 \
    && wget https://go.dev/dl/go1.21.0.linux-amd64.tar.gz \
    && rm -rf /usr/local/go \
    && tar -C /usr/local -xzf go1.21.0.linux-amd64.tar.gz \
    && rm go1.21.0.linux-amd64.tar.gz

# Set up directories
RUN mkdir -p /workspace /go

# Set up working directory
WORKDIR /workspace

# Add GPU check script
COPY scripts/gpu_check.sh /usr/local/bin/
RUN chmod +x /usr/local/bin/gpu_check.sh

# Health check for GPU availability
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD nvidia-smi > /dev/null 2>&1 || exit 1

# Copy and build the application
COPY . .
RUN go mod download && \
    go build -o /go/bin/server ./cmd/server

# Expose server port
EXPOSE 8080

# Default command to run the server
CMD ["/go/bin/server"]